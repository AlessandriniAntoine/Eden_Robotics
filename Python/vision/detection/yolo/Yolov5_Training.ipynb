{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlessandriniAntoine/Eden_Robotics/blob/ros/Python/vision/detection/yolo/Yolov5_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GD9gUQpaBxNa"
      },
      "source": [
        "# Custom Yolo Object Detector\n",
        "\n",
        "This tutorial is based on the [YOLOv5 repository](https://github.com/ultralytics/yolov5) by [Ultralytics](https://www.ultralytics.com/). \n",
        "\n",
        "To prepare your dataset, you can use [Roboflow](https://roboflow.com/) web site. It will gives you tool to annotate, split data into training, validation and test. You can also annote image locally using [labelImg](https://pypi.org/project/labelImg/) package. In that case, you upload manually data in the dataset folder.\n",
        "\n",
        "### Steps Covered in this Tutorial\n",
        "\n",
        "To train our detector we take the following steps:\n",
        "\n",
        "* Install YOLOv5 dependencies\n",
        "* Download custom YOLOv5 object detection data\n",
        "* Write our YOLOv5 Training configuration\n",
        "* Run YOLOv5 training\n",
        "* Evaluate YOLOv5 performance\n",
        "* Visualize YOLOv5 training data\n",
        "* Run YOLOv5 inference on test images\n",
        "* Export saved YOLOv5 into ONNX format for futur inference\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7mGmQbAO5pQb"
      },
      "source": [
        "#Install Dependencies\n",
        "\n",
        "_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone repo"
      ],
      "metadata": {
        "id": "r0Btj_vDVjOs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8122072e-8372-40bf-f822-bdc46e904121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'yolov5'...\n",
            "remote: Enumerating objects: 14906, done.\u001b[K\n",
            "remote: Total 14906 (delta 0), reused 0 (delta 0), pack-reused 14906\u001b[K\n",
            "Receiving objects: 100% (14906/14906), 13.95 MiB | 32.77 MiB/s, done.\n",
            "Resolving deltas: 100% (10237/10237), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ie5uLDH4uzAp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54930d50-47e4-409d-9c77-c5bd4237a3ae"
      },
      "source": [
        "# clone YOLOv5 repository\n",
        "%cd /content/yolov5\n",
        "!git reset --hard fbe67e465375231474a2ad80a4389efc77ecff99\n",
        "!pip install -qr requirements.txt  # install dependencies (ignore errors)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/yolov5\n",
            "HEAD is now at fbe67e4 Fix `OMP_NUM_THREADS=1` for macOS (#8624)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.6 MB 5.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf sample_data"
      ],
      "metadata": {
        "id": "5mIK-6WTw7L5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Packages"
      ],
      "metadata": {
        "id": "kLv69a5B07bs"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac5ec300-c83b-46ff-97e7-aa864947ed6a"
      },
      "source": [
        "# install dependencies as necessary\n",
        "import torch\n",
        "import os\n",
        "import yaml\n",
        "import google\n",
        "\n",
        "from IPython.display import Image, clear_output  # to display images\n",
        "\n",
        "# clear_output()\n",
        "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setup complete. Using torch 1.13.0+cu116 _CudaDeviceProperties(name='Tesla T4', major=7, minor=5, total_memory=15109MB, multi_processor_count=40)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Paths"
      ],
      "metadata": {
        "id": "qd9inxAQKJyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "paths = {\n",
        "    'DATASET' : '',\n",
        "    'DATASETS' : '/content/datasets',\n",
        "    'MODELS' : '/content/models',\n",
        "    'YOLOV5' : '/content/yolov5',\n",
        "}"
      ],
      "metadata": {
        "id": "-K3liyK8KJj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        !mkdir -p {path}\n",
        "  "
      ],
      "metadata": {
        "id": "wkQFutzYU3-h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "676bd1b4-9da0-4293-9f3c-09f2dd2fbfde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: missing operand\n",
            "Try 'mkdir --help' for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDIhrBF0sPaM"
      },
      "source": [
        "# Download Correctly Formatted Custom Dataset \n",
        "\n",
        "We'll download our dataset from Roboflow. Use the \"**YOLOv5 PyTorch**\" export format. Note that the Ultralytics implementation calls for a YAML file defining where your training and test data is. The Roboflow export also writes this format for us.\n",
        "\n",
        "To get your data into Roboflow, follow the [Getting Started Guide](https://blog.roboflow.ai/getting-started-with-roboflow/)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you want to use **ROBOFLOW** to upload your dataset you run the following cells"
      ],
      "metadata": {
        "id": "EVOmzDaUpiol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q roboflow"
      ],
      "metadata": {
        "id": "qEsB16MqtFy-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c39cc0e4-5c41-40cd-8e49-4fb9274068d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 45 kB 2.8 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 67 kB 2.3 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 138 kB 54.4 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 54 kB 3.2 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 178 kB 66.1 MB/s \n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 62 kB 1.6 MB/s \n",
            "\u001b[?25h  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Knxi2ncxWffW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4515bfbf-daf5-4e7e-f373-0f56b3e27423"
      },
      "source": [
        "from roboflow import Roboflow\n",
        "rf = Roboflow(model_format=\"yolov5\", notebook=\"ultralytics\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "upload and label your dataset, and get an API KEY here: https://app.roboflow.com/?model=yolov5&ref=ultralytics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['DARASET_DIRECTORY'] = paths['DATASETS']"
      ],
      "metadata": {
        "id": "j2srEO1P5tsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ug_PhK1oqwQA"
      },
      "source": [
        "%cd {paths['DATASETS']}\n",
        "#after following the link above, recieve python code with these fields filled in\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"YOU_KEY\")\n",
        "project = rf.workspace(\"eden-ssr4z\").project(\"yolov5-lovpt\")\n",
        "dataset = project.version(2).download(\"yolov5\")\n",
        "paths['DATASET'] = dataset.location"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you upload by hand your dataset, just run the next cell to precise the name of the dataset. In that case, don't forget to upload the [data.yalm]() file."
      ],
      "metadata": {
        "id": "52OQdm99UpxP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = 'Yolov5'\n",
        "paths['DATASET'] = os.path.join(paths['DATASETS'],dataset_name)\n",
        "paths['TEST'] = os.path.join(paths['DATASETS'],dataset_name,'test')\n",
        "paths['TRAIN'] = os.path.join(paths['DATASETS'],dataset_name,'train')\n",
        "paths['VALID'] = os.path.join(paths['DATASETS'],dataset_name,'valid')"
      ],
      "metadata": {
        "id": "htdVyeAKp5LA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p {paths['DATASET']}"
      ],
      "metadata": {
        "id": "BR7SloTWfG6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip {os.path.join(paths['DATASETS'],dataset_name,'test.zip')} -d {paths['TEST']}\n",
        "!rm {os.path.join(paths['DATASETS'],dataset_name,'test.zip')}\n",
        "!unzip {os.path.join(paths['DATASETS'],dataset_name,'train.zip')} -d {paths['TRAIN']}\n",
        "!rm {os.path.join(paths['DATASETS'],dataset_name,'train.zip')}\n",
        "!unzip {os.path.join(paths['DATASETS'],dataset_name,'valid.zip')} -d {paths['VALID']}\n",
        "!rm {os.path.join(paths['DATASETS'],dataset_name,'valid.zip')}"
      ],
      "metadata": {
        "id": "y_xC6wVFImDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This will create the path to the dataset depending if you used Roboflow or not"
      ],
      "metadata": {
        "id": "oPVq9HIJp5nv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Files Path"
      ],
      "metadata": {
        "id": "oXCwphX0Olcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "files = {\n",
        "    'CONFIG_YAML' : os.path.join(paths['DATASET'],'config.yaml'),\n",
        "    'DATA_YAML' : os.path.join(paths['DATASET'],'data.yaml'),\n",
        "    'DETECT_PY' : os.path.join(paths['YOLOV5'],'detect.py'),\n",
        "    'EXPORT_PY' : os.path.join(paths['YOLOV5'],'export.py'),\n",
        "    'TRAIN_PY' : os.path.join(paths['YOLOV5'],'train.py'),\n",
        "    'VAL_PY' : os.path.join(paths['YOLOV5'],'val.py'),\n",
        "}"
      ],
      "metadata": {
        "id": "9sQTK_H2OkDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZ3DmmGQztJj"
      },
      "source": [
        "# this is the YAML file Roboflow wrote for us that we're loading into this notebook with our data\n",
        "%cat {files['DATA_YAML']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UwJx-2NHsYxT"
      },
      "source": [
        "# Define Model Configuration and Architecture\n",
        "\n",
        "We will write a yaml script that defines the parameters for our model like the number of classes, anchors, and each layer.\n",
        "\n",
        "You do not need to edit these cells, but you may."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you did not use Roboflow to load your data, run the next cells"
      ],
      "metadata": {
        "id": "OPbxoHZgUq3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = ['pen','pencil','scissors','eraser']"
      ],
      "metadata": {
        "id": "8KSJvDx_UmQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_yaml = {\n",
        "    'path': paths['DATASET'],\n",
        "    'train': os.path.join('train', 'images'),\n",
        "    'val': os.path.join('valid', 'images'),\n",
        "    'test': os.path.join('test', 'images'),\n",
        "    'names': dict(enumerate(labels)),\n",
        "    'nc' : len(labels)\n",
        "}"
      ],
      "metadata": {
        "id": "rvZPNL0zUoAI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(files['DATA_YAML'], 'w') as f:\n",
        "    documents = yaml.dump(dataset_yaml, f)"
      ],
      "metadata": {
        "id": "2z73yypvUpbK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you upload data using Roboflow, run the next cell."
      ],
      "metadata": {
        "id": "xBr51q27U31y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(files['DATA_YAML'], 'r') as stream:\n",
        "    dataset_yaml  = yaml.safe_load(stream)\n",
        "dataset_yaml['path'] = paths['DATASET']\n",
        "with open(files['DATA_YAML'], 'w') as f:\n",
        "    documents = yaml.dump(dataset_yaml, f)"
      ],
      "metadata": {
        "id": "WeQR_tNtFELJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define Model Architecture\n",
        "\n",
        "We will write a yaml script that defines the parameters for our model like the number of classes, anchors, and each layer. This file is from the the yolov5 model (s,n,x...) you want to use. We just modify the number of classes."
      ],
      "metadata": {
        "id": "6-9_tnm0VBfL"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOPn9wjOAwwK"
      },
      "source": [
        "# define number of classes based on YAML\n",
        "with open(files['DATA_YAML'], 'r') as stream:\n",
        "    num_classes = str(yaml.safe_load(stream)['nc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rvt5wilnDyX"
      },
      "source": [
        "# define model type\n",
        "model_type = 'yolov5s'\n",
        "path = os.path.join(paths['YOLOV5'],'models',f'{model_type}.yaml')\n",
        "%cat {path}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t14hhyqdmw6O"
      },
      "source": [
        "#customize iPython writefile so we can write variables\n",
        "from IPython.core.magic import register_line_cell_magic\n",
        "\n",
        "@register_line_cell_magic\n",
        "def writetemplate(line, cell):\n",
        "    with open(line, 'w') as f:\n",
        "        f.write(cell.format(**globals()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uDxebz13RdRA"
      },
      "source": [
        "%%writetemplate {files['CONFIG_YAML']}\n",
        "\n",
        "# parameters\n",
        "nc: {num_classes}  # number of classes\n",
        "depth_multiple: 0.33  # model depth multiple\n",
        "width_multiple: 0.50  # layer channel multiple\n",
        "\n",
        "# anchors\n",
        "anchors:\n",
        "  - [10,13, 16,30, 33,23]  # P3/8\n",
        "  - [30,61, 62,45, 59,119]  # P4/16\n",
        "  - [116,90, 156,198, 373,326]  # P5/32\n",
        "\n",
        "# YOLOv5 v6.0 backbone\n",
        "backbone:\n",
        "  # [from, number, module, args]\n",
        "  [[-1, 1, Conv, [64, 6, 2, 2]],  # 0-P1/2\n",
        "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
        "   [-1, 3, C3, [128]],\n",
        "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
        "   [-1, 6, C3, [256]],\n",
        "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
        "   [-1, 9, C3, [512]],\n",
        "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
        "   [-1, 3, C3, [1024]],\n",
        "   [-1, 1, SPPF, [1024, 5]],  # 9\n",
        "  ]\n",
        "\n",
        "# YOLOv5 v6.0 head\n",
        "head:\n",
        "  [[-1, 1, Conv, [512, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
        "   [-1, 3, C3, [512, False]],  # 13\n",
        "\n",
        "   [-1, 1, Conv, [256, 1, 1]],\n",
        "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
        "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
        "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
        "\n",
        "   [-1, 1, Conv, [256, 3, 2]],\n",
        "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
        "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
        "\n",
        "   [-1, 1, Conv, [512, 3, 2]],\n",
        "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
        "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
        "\n",
        "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
        "  ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Model\n",
        "\n",
        "In case you want to train you model from a previous model, you can upload it in the models folder."
      ],
      "metadata": {
        "id": "fvAcDEqNJ2CP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_number = 1\n",
        "model_zip = os.path.join(paths['MODELS'],f'model_{model_number}.zip')\n",
        "model_path = os.path.join(paths['MODELS'],f'model_{model_number}')\n"
      ],
      "metadata": {
        "id": "Cni-1kzbKMbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p {model_path}\n",
        "!unzip {model_zip} -d {model_path}\n",
        "!rm {model_zip}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhW5m93FKLSl",
        "outputId": "6a9c636f-24a1-4975-89eb-08e6ce425679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/models/model_1.zip\n",
            "  inflating: /content/models/best.pt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUOiNLtMP5aG"
      },
      "source": [
        "# Train Custom YOLOv5 Detector\n",
        "\n",
        "\n",
        "Here, we are able to pass a number of arguments:\n",
        "- **img:** define input image size\n",
        "- **batch:** determine batch size\n",
        "- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n",
        "- **data:** set the path to our yaml file\n",
        "- **cfg:** specify our model configuration\n",
        "- **weights:** specify a custom path to weights. (Note, if you want to use a personnal model from where to start trainin, you have to upload it in the models folder.)\n",
        "- **name:** result names\n",
        "- **nosave:** only save the final checkpoint\n",
        "- **cache:** cache images for faster training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 416\n",
        "epochs = 350\n",
        "model_number = 1 # model from where to start, None if start from scratch"
      ],
      "metadata": {
        "id": "Vc4HLkWxRLZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if model_number is not None:\n",
        "    model_path = os.path.join(paths['MODELS'],f'model_{model_number}')\n",
        "    weights_path = os.path.join(model_path,'best.pt')\n",
        "else : \n",
        "    weights_path = ''"
      ],
      "metadata": {
        "id": "cnJST_sNRaBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    list_models = [name for name in os.listdir(paths['MODELS']) if 'model_' in name]\n",
        "    new_model_number = max(int(name[-1]) for name in list_models)+1\n",
        "except Exception:\n",
        "    new_model_number = 0\n",
        "new_model_name = os.path.join(f'model_{new_model_number}','train')"
      ],
      "metadata": {
        "id": "v9L3HHBBRnd9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(new_model_name)\n",
        "print(weights_path)"
      ],
      "metadata": {
        "id": "6x_wNWXpR0XC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1b05c7e-eafc-4a0e-f139-a6ca7b3cad88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model_2/train\n",
            "/content/models/model_1/best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/models/model_1"
      ],
      "metadata": {
        "id": "gyy_OQMGP4L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O"
      },
      "source": [
        "# train yolov5s on custom data for 100 epochs\n",
        "# time its performance\n",
        "%%time\n",
        "command = f'python {files[\"TRAIN_PY\"]} --img {img_size} --batch 16 --epochs {epochs} --data {files[\"DATA_YAML\"]} --cfg {files[\"CONFIG_YAML\"]} --project {paths[\"MODELS\"]} --name {new_model_name}'\n",
        "if weights_path : \n",
        "    command = f'{command} --weights {weights_path} --cache'\n",
        "else :\n",
        "  command = f\"{command} --weights '' --cache\"\n",
        "!{command}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJVs_4zEeVbF"
      },
      "source": [
        "# Evaluate Custom YOLOv5 Detector Performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KN5ghjE6ZWh"
      },
      "source": [
        "Training losses and performance metrics are saved to Tensorboard and also to a logfile defined above with the **--name** flag when we train. In our case, we named this `yolov5s_results`. (If given no name, it defaults to `results.txt`.) The results file is plotted as a png after training completes.\n",
        "\n",
        "\n",
        "Partially completed `results.txt` files can be plotted with `from utils.utils import plot_results; plot_results()`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_number = 2"
      ],
      "metadata": {
        "id": "0c-hyPUtSjyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_model_name = os.path.join(f'model_{model_number}','test')\n",
        "weigths_path =  os.path.join(paths['MODELS'],f'model_{model_number}','train','weights','best.pt')"
      ],
      "metadata": {
        "id": "2_kTRMWtSnIE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python {files[\"VAL_PY\"]} --weights {weigths_path} --data {files[\"DATA_YAML\"]} --img {img_size} --project {paths[\"MODELS\"]} --name {test_model_name}"
      ],
      "metadata": {
        "id": "FC-xredjSr3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a0ab3c8-7454-4145-b994-104f2f649b93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mval: \u001b[0mdata=/content/datasets/Yolov5/data.yaml, weights=['/content/models/model_2/train/weights/best.pt'], batch_size=32, imgsz=416, conf_thres=0.001, iou_thres=0.6, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=/content/models, name=model_2/test, exist_ok=False, half=False, dnn=False\n",
            "YOLOv5 ðŸš€ v6.1-306-gfbe67e4 Python-3.8.16 torch-1.13.0+cu116 CUDA:0 (Tesla T4, 15110MiB)\n",
            "\n",
            "Fusing layers... \n",
            "config summary: 213 layers, 7020913 parameters, 0 gradients, 15.8 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning '/content/datasets/Yolov5/valid/labels.cache' images and labels... 83 found, 3 missing, 0 empty, 0 corrupt: 100% 86/86 [00:00<?, ?it/s]\n",
            "               Class     Images     Labels          P          R     mAP@.5 mAP@.5:.95: 100% 3/3 [00:02<00:00,  1.05it/s]\n",
            "                 all         86         99      0.909      0.876      0.893      0.619\n",
            "                   0         86         31      0.914      0.871      0.886      0.643\n",
            "                   1         86         35       0.97      0.971      0.991      0.745\n",
            "                   2         86         18      0.944       0.93      0.941      0.524\n",
            "                   3         86         15      0.807      0.733      0.753      0.561\n",
            "Speed: 0.2ms pre-process, 4.6ms inference, 3.1ms NMS per image at shape (32, 3, 416, 416)\n",
            "Results saved to \u001b[1m/content/models/model_2/test\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOy5KI2ncnWd"
      },
      "source": [
        "# Start tensorboard\n",
        "# Launch after you have started training\n",
        "# logs save in the folder \"runs\"\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {paths['MODELS']}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3qM6T0W53gh"
      },
      "source": [
        "#Run Inference  With Trained Weights\n",
        "Run inference with a pretrained checkpoint on contents of `test/images` folder downloaded from Roboflow."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_number = 1\n",
        "conf = 0.4"
      ],
      "metadata": {
        "id": "TAfzSyk_TK9h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = os.path.join(f'model_{model_number}','detect')\n",
        "weigths_path =  os.path.join(paths['MODELS'],f'model_{model_number}','train','weights','best.pt')\n",
        "test_path = os.path.join(paths['DATASET'],'test','images')"
      ],
      "metadata": {
        "id": "ytyh0RDmTIYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nmZZnWOgJ2S"
      },
      "source": [
        "!python {files['DETECT_PY']} --weights {weigths_path} --img {img_size} --conf {conf} --source {test_path} --project {paths['MODELS']} --name {model_name}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "odKEqYtTgbRc"
      },
      "source": [
        "#display inference on ALL test images\n",
        "#this looks much better with longer training above\n",
        "\n",
        "import glob\n",
        "from IPython.display import Image, display\n",
        "\n",
        "path = os.path.join(paths['MODELS'],model_name,'*jpg')\n",
        "for imageName in glob.glob(path): #assuming JPG\n",
        "    display(Image(filename=imageName))\n",
        "    print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Export to onnx format"
      ],
      "metadata": {
        "id": "IPVhas5oHTSJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_number = 2"
      ],
      "metadata": {
        "id": "VzcOoV4OURIB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weigths_path =  os.path.join(paths['MODELS'],f'model_{model_number}','train','weights','best.pt')"
      ],
      "metadata": {
        "id": "eC8g_RDpUSiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python {files['EXPORT_PY']} --weights {weigths_path} --imgsz {img_size} {img_size} --include onnx"
      ],
      "metadata": {
        "id": "AcZgalOLHWZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall onnx --yes"
      ],
      "metadata": {
        "id": "-BVA34NDWr18",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d98841bc-864d-402c-e6cb-a4a5f5dce03f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: onnx 1.13.0\n",
            "Uninstalling onnx-1.13.0:\n",
            "  Successfully uninstalled onnx-1.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Model Data\n"
      ],
      "metadata": {
        "id": "1cM2-okuSn8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_number = 2"
      ],
      "metadata": {
        "id": "NKJAvAW9Sscb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = os.path.join(paths['MODELS'],f'model_{model_number}')\n",
        "zip_name = f'model_{model_number}.zip'"
      ],
      "metadata": {
        "id": "oSiiDSXxStvp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ckMpLuLT0wmY",
        "outputId": "a783227b-a703-4b09-a8c1-e2e24cc3f1fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/models/model_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd {model_path} && zip -r {zip_name} test train"
      ],
      "metadata": {
        "id": "0C4RA3RlS6JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "google.colab.files.download(os.path.join(model_path,f'model_{model_number}.zip')) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ZvuIElxAS1VH",
        "outputId": "f5246062-8630-4ce6-fdce-ea09ca9658e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_86ad9a85-a115-402b-9a50-918db0ad74b0\", \"model_2.zip\", 57770304)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uPq9mVgiBql"
      },
      "source": [
        "# Export Trained Weights for Future Inference\n",
        "\n",
        "Now that you have trained your custom detector, you can export the trained weights you have made here for inference on your device elsewhere"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YH4CTzDRh00g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcac05aa-7bb2-40bb-d1ba-cf8b2d30a4f2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x_wg3VeiXMW"
      },
      "source": [
        "%cp /content/yolov5/runs/train/yolov5s_results/weights/best.pt /content/gdrive/My\\ Drive"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}