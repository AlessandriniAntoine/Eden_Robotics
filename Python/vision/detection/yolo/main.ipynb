{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Yolo Object Detector\n",
    "\n",
    "This notebook allow you to create a yolo5 classifier. A virtual environment is required to simplify the creation. \n",
    "\n",
    "## Virtual environnement \n",
    "Creation virtual environnement and install package to use jupyter notebook:\n",
    "```console\n",
    "python -m venv env\n",
    "source ./env/bin/activate\n",
    "python -m pip install --upgrade pip\n",
    "pip install ipykernel\n",
    "python -m ipykernel install --user --name=env\n",
    "```\n",
    "\n",
    "Then one the jupyter notebook select the correct kernel.\n",
    "\n",
    "\n",
    "## Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "DIR_PATH = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'DATA_PATH' : os.path.join(DIR_PATH,'data'),\n",
    "    'DOWNLOADED_IMAGES' : os.path.join(DIR_PATH,'data','images','download'),\n",
    "    'IMAGES_PATH' : os.path.join(DIR_PATH,'data', 'images'),\n",
    "    'LABELIMG_PATH' : os.path.join(DIR_PATH, 'labelimg'),\n",
    "    'MODELS_PATHS' : os.path.join(DIR_PATH,'data','models'),\n",
    "    'TRAIN_PATH' : os.path.join(DIR_PATH,'data','train'),\n",
    "    'TRAIN_IMAGES_PATH' : os.path.join(DIR_PATH,'data','train','images'),\n",
    "    'TRAIN_LABELS_PATH' : os.path.join(DIR_PATH,'data','train','labels'),\n",
    "    'TEST_PATH' : os.path.join(DIR_PATH,'data','test'),\n",
    "    'TEST_IMAGES_PATH' : os.path.join(DIR_PATH,'data','test','images'),\n",
    "    'TEST_LABELS_PATH' : os.path.join(DIR_PATH,'data','test','labels'),\n",
    "    'YOLO5_PATH' : os.path.join(DIR_PATH,'yolov5'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'CASCADE_TXT' : os.path.join(paths['DATA_PATH'],'cascade.txt'),\n",
    "    'CLASSES_TXT' : os.path.join(paths['IMAGES_PATH'],'classes.txt'),\n",
    "    'DATASET_YAML' : os.path.join(paths['DATA_PATH'],'dataset.yaml'),\n",
    "    'EXPORT_PY' : os.path.join(paths['YOLO5_PATH'],'export.py'),    \n",
    "    'FILTER_PY' : os.path.join(DIR_PATH,'filter.py'),\n",
    "    'LABELIMG_PY' : os.path.join(paths['LABELIMG_PATH'],'labelImg.py'),\n",
    "    'PREDIFINED_CLASSES_TXT' : os.path.join(paths['LABELIMG_PATH'],'data','predifined_classes.txt'),\n",
    "    'TRAIN_PY' : os.path.join(paths['YOLO5_PATH'],'train.py'),\n",
    "    'VALIDATE_PY' : os.path.join(paths['YOLO5_PATH'],'val.py'),\n",
    "    'YOLON_PT' : os.path.join(paths['YOLO5_PATH'],'yolov5n.pt'),\n",
    "    'YOLOS_PT' : os.path.join(paths['YOLO5_PATH'],'yolov5s.pt')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Dependencies\n",
    "\n",
    "See pytorch [page](https://pytorch.org/get-started/locally/) to download the correct version with or without gpu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cpu\n",
    "!pip install protobuf==3.19.6 opencv-python pyyaml comet_ml bs4 requests matplotlib\n",
    "!pip install pyqt5 lxml --upgrade"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we download the yolo5 repository. Only the 5s model is there but you can see the [github](https://github.com/ultralytics/yolov5) and download more model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.listdir(paths['YOLO5_PATH']):\n",
    "    !git clone https://github.com/ultralytics/yolov5 {paths['YOLO5_PATH']}\n",
    "    !cd {paths['YOLO5_PATH']} && pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.listdir(paths['LABELIMG_PATH']):\n",
    "    !git clone https://github.com/tzutalin/labelImg {paths['LABELIMG_PATH']}\n",
    "    !cd {paths['LABELIMG_PATH']} && pyrcc5 -o libs/resources.py resources.qrc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import requests \n",
    "from bs4 import *\n",
    "\n",
    "import torch\n",
    "import cv2\n",
    "\n",
    "import yaml\n",
    "import contextlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Images from URL\n",
    "\n",
    "See this [link](https://www.123rf.com/) from where you can download images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_images(images, folder_name):\n",
    "    print(f\"Total {len(images)} Image Found!\")\n",
    "    if len(images) != 0:\n",
    "        count = 0\n",
    "        for image in images:\n",
    "            try:\n",
    "                image_link = image[\"data-srcset\"]\n",
    "            except Exception:\n",
    "                try:\n",
    "                    image_link = image[\"data-src\"]\n",
    "                except Exception:\n",
    "                    try:\n",
    "                        image_link = image[\"data-fallback-src\"]\n",
    "                    except Exception:\n",
    "                        with contextlib.suppress(Exception):\n",
    "                            image_link = image[\"src\"]\n",
    "\n",
    "            with contextlib.suppress(Exception):\n",
    "                r = requests.get(image_link).content\n",
    "                try:\n",
    "                    r = str(r, 'utf-8')\n",
    "                except UnicodeDecodeError:\n",
    "                    with open(f'{folder_name}/{time.strftime(\"%Y%m%d_%H%M%S\")}.jpg', \"wb+\") as f:\n",
    "                        f.write(r)\n",
    "                    count += 1\n",
    "        print(f\"Total {count} Images Downloaded Out of {len(images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    images = soup.findAll('img')\n",
    "    download_images(images,folder_name=os.path.join(paths['IMAGES_PATH'],'URL'))\n",
    "else :\n",
    "    print('URL not valide')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Downloaded Images\n",
    "\n",
    "Images are downloaded from internet, it might be wrong images. Launch the next command (on a terminal) and you can select between tomato, background or deleting the image. It will go throw all the images downloaded and move the one you want to keep in the images folder.\n",
    "\n",
    "If you want to use it for other label, you need to modify  the [filter](./filter.py) file. \n",
    "\n",
    "In the images folder, you image need to be name **label.img_name.jpg**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f'python {files[\"FILTER_PY\"]} -i {paths[\"DOWNLOADED_IMAGES\"]} -s {paths[\"IMAGES_PATH\"]}'\n",
    "print(command)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resize image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(img_path,dimension):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.resize(img,dimension,cv2.INTER_AREA)\n",
    "    cv2.imwrite(img_path,img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = (416,416)\n",
    "folder = paths['TEST_IMAGES_PATH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in os.listdir(folder):\n",
    "    if file.endswith('.jpg'):\n",
    "        img_path = os.path.join(folder,file)\n",
    "        resize_image(img_path,dimension)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Images\n",
    "\n",
    "Check that format is YOLO when you labelize your images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(files['CLASSES_TXT']):\n",
    "    classes_file_path = files['CLASSES_TXT']\n",
    "else :\n",
    "    classes_file_path = files['PREDIFINED_CLASSES_TXT']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f'python {files[\"LABELIMG_PY\"]} {paths[\"IMAGES_PATH\"]} {classes_file_path} {paths[\"IMAGES_PATH\"]}'\n",
    "print(command)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfert images in train and test folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_up(n):\n",
    "    return int(n)+bool(n%1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = os.listdir(paths['IMAGES_PATH'])\n",
    "try:\n",
    "    list_files.remove('classes.txt')\n",
    "except Exception:\n",
    "    print('No classes defined. Please label images')\n",
    "list_names = [file.split('.') for file in list_files if file.endswith('txt')]\n",
    "list_names = {f'{name[0]}.{name[1]}' for name in list_names}\n",
    "test =  set(random.sample(list_names, round_up(test_size*len(list_names))))\n",
    "train = list_names - test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in list(train) :\n",
    "    src_path = os.path.join(paths['IMAGES_PATH'],f'{file_name}.txt')\n",
    "    dst_path = os.path.join(paths['TRAIN_LABELS_PATH'],f'{file_name}.txt')\n",
    "    shutil.move(src_path, dst_path)\n",
    "    src_path = os.path.join(paths['IMAGES_PATH'],f'{file_name}.jpg')\n",
    "    dst_path = os.path.join(paths['TRAIN_IMAGES_PATH'],f'{file_name}.jpg')\n",
    "    shutil.move(src_path, dst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file_name in list(test) :\n",
    "    src_path = os.path.join(paths['IMAGES_PATH'],f'{file_name}.txt')\n",
    "    dst_path = os.path.join(paths['TEST_LABELS_PATH'],f'{file_name}.txt')\n",
    "    shutil.move(src_path, dst_path)\n",
    "    src_path = os.path.join(paths['IMAGES_PATH'],f'{file_name}.jpg')\n",
    "    dst_path = os.path.join(paths['TEST_IMAGES_PATH'],f'{file_name}.jpg')\n",
    "    shutil.move(src_path, dst_path)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No backgroung (image without label) have been added but it can be done manually"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images Augmentation\n",
    "\n",
    "In case you dataset is not big enough, you can increase it by : \n",
    "- flip some images horizontally or vertically if possible\n",
    "- rescale and crop image to keep the define size\n",
    "\n",
    "Here, only horizontally flipping has been implemented. The label file is also generated from the one of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_proba = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_files = os.listdir(paths['TRAIN_IMAGES_PATH'])\n",
    "list_names = [file.split('.') for file in list_files if 'tomato' in file]\n",
    "list_names = {f'{name[0]}.{name[1]}' for name in list_names}\n",
    "flipped =  set(random.sample(list_names, round_up(flipped_proba*len(list_names)))))\n",
    "unmove = list_names-flipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_name in list(flipped):\n",
    "\n",
    "    img_path = os.path.join(paths['TRAIN_IMAGES_PATH'],f'{img_name}.jpg')\n",
    "    label_path = os.path.join(paths['TRAIN_LABELS_PATH'],f'{img_name}.txt')\n",
    "    img_flip_path = os.path.join(paths['TRAIN_IMAGES_PATH'],'output',f'{img_name}_flipped.jpg')\n",
    "    label_flip_path = os.path.join(paths['TRAIN_LABELS_PATH'],'output',f'{img_name}_flipped.txt')\n",
    "\n",
    "    img = cv2.imread(img_path)\n",
    "    img_flip = cv2.flip(img, 1)\n",
    "\n",
    "    with open(label_path) as f:\n",
    "        labels = [line.rstrip() for line in f]\n",
    "    with open(label_flip_path,'w') as f:\n",
    "        for line in labels:\n",
    "            line_split = line.split(' ')\n",
    "            line_split[1] = str(1-float(line_split[1]))\n",
    "            line = \" \".join(line_split)\n",
    "\n",
    "            f.write(line)\n",
    "            f.write('\\n')\n",
    "    cv2.imwrite(img_flip_path, img_flip)\n",
    "    print(f'Image {img_path} flipped into {img_name}_flipped')\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write Dataset File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(files['CLASSES_TXT']) as f:\n",
    "    labels = [line.rstrip() for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_yaml = {\n",
    "    'path' : paths['DATA_PATH'],\n",
    "    'train' : os.path.join('train','images'),\n",
    "    'val' : os.path.join('test','images'),\n",
    "    'test' : os.path.join('test','images'),\n",
    "    'names' : {i:label for i,label in enumerate(labels)}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(files['DATASET_YAML'], 'w') as file:\n",
    "    documents = yaml.dump(dataset_yaml, file)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "It is better to run the training command in a terminal to see the output but last case will print the command and you just have to copy paste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 416\n",
    "batch = 16\n",
    "epochs = 350\n",
    "workers = 2\n",
    "yolo_model_type = 'n' #n or s\n",
    "use_previous_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select model from where we start (if use_previous model)\n",
    "model_number = 0\n",
    "model_path = os.path.join(paths['MODELS_PATHS'],'train',f'model_{model_number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if use_previous_model:\n",
    "    pt_model_path = os.path.join(model_path,'weights','best.pt')\n",
    "elif yolo_model_type == 'n':\n",
    "    pt_model_path = files['YOLON_PT']\n",
    "elif yolo_model_type == 's':\n",
    "    pt_model_path = files['YOLOS_PT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new model path\n",
    "model_number = max(int(name[-1]) for name in os.listdir(os.path.join(paths['MODELS_PATHS'],'train')))+1\n",
    "new_model_path = os.path.join(paths['MODELS_PATHS'],'train',f'model_{model_number}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pt_model_path)\n",
    "print(new_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f'python {files[\"TRAIN_PY\"]} --img {img_size} --batch {batch} --epochs {epochs} --data {files[\"DATASET_YAML\"]} --weights {pt_model_path} --workers {workers} --project {paths[\"MODELS_PATHS\"]} --name {new_model_path}'\n",
    "print(command)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_number = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model_path = os.path.join(paths['MODELS_PATHS'],'test',f'model_{model_number}')\n",
    "weigths_path =  os.path.join(paths['MODELS_PATHS'],'train',f'model_{model_number}','weights','best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "command = f'python {files[\"VALIDATE_PY\"]} --weights {weigths_path} --data {files[\"DATASET_YAML\"]} --img {img_size} --project {paths[\"MODELS_PATHS\"]} --name {test_model_path}'\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir {new_model_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_number = 0\n",
    "if os.listdir(os.path.join(paths['MODELS_PATHS'],'train')):\n",
    "    model_number = max(int(name[-1]) for name in os.listdir(os.path.join(paths['MODELS_PATHS'],'train')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_number = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(paths['MODELS_PATHS'],'train',f'model_{model_number}')\n",
    "weigths_path = os.path.join(model_path,'weights','best.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_path)\n",
    "print(weigths_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'custom', path=weigths_path, force_reload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.conf = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image in os.listdir(paths['TEST_IMAGES_PATH']):\n",
    "    results = model(os.path.join(paths['TEST_IMAGES_PATH'],image))\n",
    "    results.print()\n",
    "    %matplotlib inline \n",
    "    plt.imshow(np.squeeze(results.render()))\n",
    "    plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Live Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame,dimension)\n",
    "    # Make detections \n",
    "    results = model(frame)\n",
    "    results_frame = np.squeeze(results.render())\n",
    "\n",
    "    new_frame_time = time.time()\n",
    "    fps = round(1/(new_frame_time-prev_frame_time),2)\n",
    "    prev_frame_time = new_frame_time\n",
    "    cv2.putText(results_frame, f'FPS : {fps}Hz', (2, 20), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (100, 255, 0), 1, cv2.LINE_AA)\n",
    "    cv2.imshow('YOLO', results_frame)\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Yolo Label To Cascade Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo2cascade(cascade_file,img_path,label_path):\n",
    "    for file in os.listdir(label_path):\n",
    "        if file not in ['classes.txt', 'output']:\n",
    "\n",
    "            # get path image\n",
    "            jpg = file.split('.')\n",
    "            jpg = os.path.join(img_path,f'{jpg[0]}.{jpg[1]}.jpg')\n",
    "\n",
    "            # get yolo txt and image\n",
    "            with open(os.path.join(label_path,file)) as yolo_file:\n",
    "                yolo_format = [line.rstrip() for line in yolo_file]\n",
    "            yolo_format = [tomato.split(' ') for tomato in yolo_format]\n",
    "            img = cv2.imread(jpg)\n",
    "            img_shape = img.shape\n",
    "\n",
    "            # yolo format to cascade format\n",
    "            cascade_format = []\n",
    "            for tomato in yolo_format:\n",
    "                x_c,y_c = int(float(tomato[1])*img_shape[1]),int(float(tomato[2])*img_shape[0])\n",
    "                w,h = int(float(tomato[3])*img_shape[1]),int(float(tomato[4])*img_shape[0])\n",
    "                x,y = int(x_c-w/2), int(y_c-h/2)\n",
    "                cascade_format.append([str(x),str(y),str(w),str(h)])\n",
    "\n",
    "            # write in text file\n",
    "            line = [file]\n",
    "            for tomato in cascade_format:\n",
    "                line.extend(tomato)\n",
    "            line = \" \".join(line)\n",
    "            cascade_file.write(line)\n",
    "            cascade_file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(files['CASCADE_TXT'],'w') as cascade_file:\n",
    "    yolo2cascade(cascade_file,paths['TRAIN_IMAGES_PATH'],paths['TRAIN_LABELS_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data/cascade_test.txt','w') as cascade_file:\n",
    "    yolo2cascade(cascade_file,paths['TEST_IMAGES_PATH'],paths['TEST_LABELS_PATH'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stat label size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(files['CASCADE_TXT']) as f:\n",
    "    cascade_file = [line.rstrip() for line in f]\n",
    "with open('./data/cascade_test.txt') as f:\n",
    "    cascade_file += [line.rstrip() for line in f]\n",
    "tomatoes,x_distrib,y_distrib,w_distrib,h_distrib = [],[],[],[],[]\n",
    "for line in cascade_file:\n",
    "    tomato_list = line.split(' ')[1:] \n",
    "    tomato_list = [tomato_list[4*i:4*(i+1)] for i in range(len(tomato_list)//4)]\n",
    "    for tomato in tomato_list : \n",
    "        x_distrib.append(int(tomato[0]))\n",
    "        y_distrib.append(int(tomato[1]))\n",
    "        w_distrib.append(int(tomato[2]))\n",
    "        h_distrib.append(int(tomato[3]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(2, 2, figsize=(12, 7))\n",
    "figure.suptitle('Label distribution', fontsize=16)\n",
    "\n",
    "# For Sine Function\n",
    "axis[0, 0].hist(x_distrib, bins = 50,color = 'blue', edgecolor = 'black')\n",
    "axis[0, 0].set_title(\"X center\",size=10)\n",
    "axis[0, 0].set_xlabel(\"x (pixel)\")\n",
    "axis[0, 0].set_ylabel(\"count\")\n",
    "\n",
    "# For Cosine Function\n",
    "axis[0, 1].hist(y_distrib, bins = 50,color = 'blue', edgecolor = 'black')\n",
    "axis[0, 1].set_title(\"Y center\",size=10)\n",
    "axis[0, 1].set_xlabel(\"y (pixel)\")\n",
    "axis[0, 1].set_ylabel(\"count\")\n",
    "\n",
    "# For Tangent Function\n",
    "axis[1, 0].hist(w_distrib, bins = 100,color = 'blue', edgecolor = 'black')\n",
    "axis[1, 0].set_title(\"Width\",size=10)\n",
    "axis[1, 0].set_xlabel(\"w (pixel)\")\n",
    "axis[1, 0].set_ylabel(\"count\")\n",
    "\n",
    "# For Tanh Function\n",
    "axis[1, 1].hist(h_distrib, bins = 100,color = 'blue', edgecolor = 'black')\n",
    "axis[1, 1].set_title(\"Height\",size=10)\n",
    "axis[1, 1].set_xlabel(\"h (pixel)\")\n",
    "axis[1, 1].set_ylabel(\"count\")\n",
    "\n",
    "# Combine all the operations and display\n",
    "figure.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_array(array,offset):\n",
    "  filter_array = []\n",
    "  # go through each element in arr\n",
    "  for element in array:\n",
    "    # if the element is higher than 42, set the value to True, otherwise False:\n",
    "    if element < offset:\n",
    "      filter_array.append(True)\n",
    "    else:\n",
    "      filter_array.append(False)\n",
    "  array = np.array(array)\n",
    "  array = array[filter_array]\n",
    "  return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_filter = filter_array(w_distrib,100)\n",
    "h_filter = filter_array(h_distrib,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure, axis = plt.subplots(2, 1, figsize=(12, 7))\n",
    "figure.suptitle('Label distribution', fontsize=16)\n",
    "\n",
    "# For Sine Function\n",
    "axis[0].hist(w_filter, bins = 100,color = 'blue', edgecolor = 'black')\n",
    "axis[0].set_title(\"Width\",size=10)\n",
    "axis[0].set_xlabel(\"w (pixel)\")\n",
    "axis[0].set_ylabel(\"count\")\n",
    "\n",
    "# For Cosine Function\n",
    "axis[1].hist(h_filter, bins = 100,color = 'blue', edgecolor = 'black')\n",
    "axis[1].set_title(\"Height\",size=10)\n",
    "axis[1].set_xlabel(\"h (pixel)\")\n",
    "axis[1].set_ylabel(\"count\")\n",
    "\n",
    "# Combine all the operations and display\n",
    "figure.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07327c2a105b4dea974e16ef4c85f42152fc3e54f3fb9f73af78e630bbe79aed"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
