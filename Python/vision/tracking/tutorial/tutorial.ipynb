{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Tracking Algorithm Tutorial\n",
    "\n",
    "This notebook present all the tracking techniques available with opencv and how to use them.\n",
    "\n",
    "## Virtual environnement\n",
    "Creation virtual environnement and install package to use jupyter notebook:\n",
    "```console\n",
    "python -m venv env\n",
    "source ./env/bin/activate\n",
    "python -m pip install --upgrade pip\n",
    "pip install ipykernel\n",
    "python -m ipykernel install --user --name=env\n",
    "```\n",
    "Then one the jupyter notebook select the correct kernel.\n",
    "\n",
    "## Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python opencv-contrib-python matplotlib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "from random import randint\n",
    "import numpy as np\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_NAME = os.getcwd()\n",
    "paths = {\n",
    "    'DATA_PATH' : os.path.join(DIR_NAME,'data'),\n",
    "    'VIDEOS_PATH' : os.path.join(DIR_NAME,'data','videos'),\n",
    "    'CASCADE_PATH' : os.path.join(DIR_NAME,'data','cascade')  # only if you have a cascade file\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'GOTURN_CAFFEMODEL' : os.path.join(paths['DATA_PATH'],'goturn.caffemodel'),\n",
    "    'GOTURN_PROTOTXT' : os.path.join(paths['DATA_PATH'],'goturn.prototxt'),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_types = ['BOOSTING', 'MIL', 'KCF', 'TLD', 'MEDIANFLOW', 'MOSSE', 'CSRT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tracker_by_name(tracker_type):\n",
    "    if tracker_type == tracker_types[0]:\n",
    "        tracker = cv2.legacy.TrackerBoosting_create()\n",
    "    elif tracker_type == tracker_types[1]:\n",
    "        tracker = cv2.legacy.TrackerMIL_create()\n",
    "    elif tracker_type == tracker_types[2]:\n",
    "        tracker = cv2.legacy.TrackerKCF_create()\n",
    "    elif tracker_type == tracker_types[3]:\n",
    "        tracker = cv2.legacy.TrackerTLD_create()\n",
    "    elif tracker_type == tracker_types[4]:\n",
    "        tracker = cv2.legacy.TrackerMedianFlow_create()\n",
    "    elif tracker_type == tracker_types[5]:\n",
    "        tracker = cv2.legacy.TrackerMOSSE_create()\n",
    "    elif tracker_type == tracker_types[6]:\n",
    "        tracker = cv2.legacy.TrackerCSRT_create()\n",
    "    else:\n",
    "        tracker = None\n",
    "        print('Invalid name! Available trackers: ')\n",
    "        for t in tracker_types:\n",
    "            print(t)\n",
    "    return tracker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_type = 'CSRT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker = create_tracker_by_name(tracker_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'race.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open video\n",
    "video = cv2.VideoCapture(os.path.join(paths['VIDEOS_PATH'],video_name))\n",
    "if not video.isOpened():\n",
    "    print('Error while loading the video!')\n",
    "    sys.exit()\n",
    "flag, frame = video.read()\n",
    "if not flag:\n",
    "    print('Erro while loading the frame!')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n"
     ]
    }
   ],
   "source": [
    "bbox = cv2.selectROI(frame) # region of interest\n",
    "cv2.destroyAllWindows()\n",
    "flag = tracker.init(frame, bbox)\n",
    "if not flag:\n",
    "    print('Error while initializing tracker.')\n",
    "colors = (randint(0, 255), randint(0,255), randint(0, 255)) # RGB -> BGR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_frame_time, new_frame_time = 0, 0\n",
    "while True:\n",
    "    ok, frame = video.read()\n",
    "    #print(ok)\n",
    "    if not ok:\n",
    "        break\n",
    "\n",
    "    ok, bbox = tracker.update(frame)\n",
    "    #print(ok, bbox)\n",
    "    if ok == True:\n",
    "        (x, y, w, h) = [int(v) for v in bbox]\n",
    "        #print(x, y, w, h)\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), colors, 2)\n",
    "    else:\n",
    "        cv2.putText(frame, 'Tracking failure!', (100,80), cv2.FONT_HERSHEY_SIMPLEX, .75, (0,0,255))\n",
    "\n",
    "    new_frame_time = time.time()\n",
    "    fps = round(1/(new_frame_time-prev_frame_time),2)\n",
    "    prev_frame_time = new_frame_time\n",
    "    cv2.putText(frame,f'Tracker : {tracker_type}, FPS : {fps}HZ', (100, 20), cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255))\n",
    "\n",
    "    cv2.imshow('Tracking', frame)\n",
    "    if cv2.waitKey(1) & 0XFF == 27: # esc\n",
    "        break\n",
    "    \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'race.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open video\n",
    "video = cv2.VideoCapture(os.path.join(paths['VIDEOS_PATH'],video_name))\n",
    "if not video.isOpened():\n",
    "    print('Error while loading the video!')\n",
    "    sys.exit()\n",
    "flag, frame = video.read()\n",
    "if not flag:\n",
    "    print('Erro while loading the frame!')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n",
      "Press Q to quit and start tracking\n",
      "Press any other key to select the next object\n",
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n",
      "Press Q to quit and start tracking\n",
      "Press any other key to select the next object\n",
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n",
      "Press Q to quit and start tracking\n",
      "Press any other key to select the next object\n",
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n",
      "Press Q to quit and start tracking\n",
      "Press any other key to select the next object\n"
     ]
    }
   ],
   "source": [
    "# define bounding boxes to track\n",
    "bboxes = []\n",
    "colors = []\n",
    "while True:\n",
    "    bbox = cv2.selectROI('MultiTracker', frame)\n",
    "    bboxes.append(bbox)\n",
    "    colors.append((randint(0,255), randint(0,255), randint(0,255)))\n",
    "    print('Press Q to quit and start tracking')\n",
    "    print('Press any other key to select the next object')\n",
    "    k = cv2.waitKey(0) & 0XFF\n",
    "    if k == 113: # Q - quit\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_type = 'CSRT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init tracker\n",
    "multi_tracker = cv2.legacy.MultiTracker_create()\n",
    "for bbox in bboxes:\n",
    "    multi_tracker.add(create_tracker_by_name(tracker_type), frame, bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform tracking\n",
    "prev_frame_time, new_frame_time = 0, 0\n",
    "while video.isOpened():\n",
    "    flag, frame = video.read()\n",
    "    if not flag:\n",
    "        break\n",
    "\n",
    "    flag, boxes = multi_tracker.update(frame)\n",
    "\n",
    "    if flag : \n",
    "        for i, box in enumerate(boxes):\n",
    "            (x, y, w, h) = [int(v) for v in box]\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), colors[i], 2)\n",
    "    else :\n",
    "        cv2.putText(frame, 'Tracking failure!', (100,80), cv2.FONT_HERSHEY_SIMPLEX, .75, (0,0,255))\n",
    " \n",
    "    new_frame_time = time.time()\n",
    "    fps = round(1/(new_frame_time-prev_frame_time),2)\n",
    "    prev_frame_time = new_frame_time\n",
    "    cv2.putText(frame,f'Tracker : {tracker_type}, FPS : {fps}HZ', (100, 20), cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255))\n",
    "\n",
    "    cv2.imshow('MultiTracker', frame)\n",
    "    if cv2.waitKey(1) & 0XFF == 27: # esc\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goturn Tracking\n",
    "\n",
    "Use deep learning model, need two file \n",
    "- [coffemodel](./goturn.caffemodel) : contains the weight\n",
    "- [prototxt](./goturn.prototxt) : contains the data\n",
    "\n",
    "To be sure to get good result, you need to be sure the object you track is in the training dataset of the model because it is an offline model.\n",
    "\n",
    "Go to this [repository](https://github.com/spmallick/goturn-files.git) to download examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not (os.path.isfile(files['GOTURN_CAFFEMODEL']) and os.path.isfile(files['GOTURN_PROTOTXT'])):\n",
    "    print('Error loading the network files!')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tracker\n",
    "tracker = cv2.TrackerGOTURN_create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'race.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load video and first frame\n",
    "video = cv2.VideoCapture(os.path.join(paths['VIDEOS_PATH'],video_name))\n",
    "if not video.isOpened():\n",
    "    print('Error while loading the video!')\n",
    "    sys.exit()\n",
    "flag, frame = video.read()\n",
    "if not flag:\n",
    "    print('Erro while loading the frame!')\n",
    "    sys.exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n"
     ]
    }
   ],
   "source": [
    "# init bounding box and tracker\n",
    "bbox = cv2.selectROI(frame) # region of interest\n",
    "cv2.destroyAllWindows()\n",
    "colors = (randint(0, 255), randint(0, 255), randint(0, 255))\n",
    "flag = tracker.init(frame, bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform tracking\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "while True:\n",
    "    flag, frame = video.read()\n",
    "    if not flag:\n",
    "        break\n",
    "\n",
    "    flag, bbox = tracker.update(frame)\n",
    "    if flag == True:\n",
    "        (x, y, w, h) = [int(v) for v in bbox]\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), colors, 2)\n",
    "    else:\n",
    "        cv2.putText(frame, 'Tracking failure!', (100,80), cv2.FONT_HERSHEY_SIMPLEX, .75, (0,0,255))\n",
    "\n",
    "    new_frame_time = time.time()\n",
    "    fps = round(1/(new_frame_time-prev_frame_time),2)\n",
    "    prev_frame_time = new_frame_time\n",
    "    cv2.putText(frame,f'Tracker : GOTURN, FPS : {fps}HZ', (100, 20), cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255))\n",
    "\n",
    "    cv2.imshow('Tracking', frame)\n",
    "    if cv2.waitKey(1) & 0XFF == 27: # esc\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object Detection\n",
    "\n",
    "To improve you tracking, you can use object detection. If your tracker tell you when you have lost you the object, you can perform object detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracker_type = 'CRST'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'walking.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init video and tracker\n",
    "tracker = create_tracker_by_name(tracker_type)\n",
    "video = cv2.VideoCapture(os.path.join(paths['VIDEOS_PATH'],video_name))\n",
    "if not video.isOpened():\n",
    "    print('Error while loading the video!')\n",
    "    sys.exit()\n",
    "flag, frame = video.read()\n",
    "if not flag:\n",
    "    print('Erro while loading the frame!')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init detector\n",
    "cascade_name = 'fullbody.xml'\n",
    "detector = cv2.CascadeClassifier(os.path.join(paths['CASCADE_PATH'],cascade_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect():\n",
    "    while True:\n",
    "        flag, frame = video.read()\n",
    "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        # change function if detector change\n",
    "        detections = detector.detectMultiScale(frame_gray, minSize=(60,60)) \n",
    "        for (x, y, w, h) in detections:\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0,0,255), 2)\n",
    "            cv2.imshow('Detection', frame)\n",
    "            if x > 0:\n",
    "                print('Haarscade detection')\n",
    "                return x, y, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init bounding box and tracking\n",
    "bbox = detect()\n",
    "flag = tracker.init(frame, bbox)\n",
    "colors = (randint(0, 255), randint(0, 255), randint(0, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform tracking and detection\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "while True:\n",
    "    flag, frame = video.read()\n",
    "    if not flag:\n",
    "        break\n",
    "    flag, bbox = tracker.update(frame)\n",
    "    if flag:\n",
    "        (x, y, w, h) = [int(v) for v in bbox]\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), colors)\n",
    "    else:\n",
    "        print('Tracking failure! We will execute the haarcascade detector')\n",
    "        bbox = detect()\n",
    "        tracker = create_tracker_by_name(tracker_type)\n",
    "        tracker.init(frame, bbox)\n",
    "\n",
    "    new_frame_time = time.time()\n",
    "    fps = round(1/(new_frame_time-prev_frame_time),2)\n",
    "    prev_frame_time = new_frame_time\n",
    "    cv2.putText(frame,f'Tracker : {tracker_type}, FPS : {fps}HZ', (100, 20), cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255))\n",
    "\n",
    "    cv2.imshow('Tracking', frame)\n",
    "    k = cv2.waitKey(1) & 0XFF\n",
    "    if k == 27: # esc\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MeanShift\n",
    "\n",
    "Useful links:\n",
    "- [hsv color space](https://cran.r-project.org/web/packages/colordistance/vignettes/color-spaces.html)\n",
    "- [opencv color space](https://www.learnopencv.com/color-spaces-in-opencv-cpp-python/)\n",
    "- [opencv histogram](https://docs.opencv.org/master/d1/db7/tutorial_py_histogram_begins.html)\n",
    "- [opencv back projection](https://docs.opencv.org/3.4.15/da/d7f/tutorial_back_projection.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Select a ROI and then press SPACE or ENTER button!\n",
      "Cancel the selection process by pressing c button!\n"
     ]
    }
   ],
   "source": [
    "# initialise camera and bounding box\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not video.isOpened():\n",
    "    print('Error while loading the video!')\n",
    "    sys.exit()\n",
    "time.sleep(1.5)\n",
    "flag, frame = cap.read()\n",
    "if not flag:\n",
    "    print('Erro while loading the frame!')\n",
    "    sys.exit()\n",
    "bbox = cv2.selectROI(frame)\n",
    "cv2.destroyAllWindows()\n",
    "x, y, w, h = bbox\n",
    "track_window = (x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = (randint(0, 255), randint(0, 255), randint(0, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute hsv histogram\n",
    "roi = frame[y:y+h, x:x+w] # RGB -> BGR\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], None, [180], [0,180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show histogram\n",
    "plt.hist(roi.ravel(), 180, [0, 180])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_hist = cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "# define (param1|param2...),value1,value2...\n",
    "parameters = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform tracking\n",
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "while True:\n",
    "    flag, frame = cap.read()\n",
    "    if flag:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        dst = cv2.calcBackProject([hsv], [0], roi_hist, [0,180], 1)\n",
    "        flag, track_window = cv2.meanShift(dst, (x, y, w, h), parameters)\n",
    "        if flag:\n",
    "            x, y, w, h = track_window\n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), colors, 2)\n",
    "        else:\n",
    "            cv2.putText(frame, 'Tracking failure!', (100,80), cv2.FONT_HERSHEY_SIMPLEX, .75, (0,0,255))\n",
    "\n",
    "        new_frame_time = time.time()\n",
    "        fps = round(1/(new_frame_time-prev_frame_time),2)\n",
    "        prev_frame_time = new_frame_time\n",
    "        cv2.putText(frame,f'Tracker : MeanShift, FPS : {fps}HZ', (100, 20), cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255))\n",
    "\n",
    "        cv2.imshow('Meanshift tracking', frame)\n",
    "        cv2.imshow('Meanshift distribution', dst)\n",
    "\n",
    "\n",
    "        if cv2.waitKey(1) == 13: # esc\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CamShift\n",
    "\n",
    "Update of MeanShift as it adapt the size of the bounding box.\n",
    "Useful Links : \n",
    "- [opencv polylines](https://docs.opencv.org/4.5.3/d6/d6e/group__imgproc__draw.html#ga1ea127ffbbb7e0bfc4fd6fd2eb64263c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise camera and bounding box\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not video.isOpened():\n",
    "    print('Error while loading the video!')\n",
    "    sys.exit()\n",
    "time.sleep(1.5)\n",
    "flag, frame = cap.read()\n",
    "if not flag:\n",
    "    print('Erro while loading the frame!')\n",
    "    sys.exit()\n",
    "bbox = cv2.selectROI(frame)\n",
    "cv2.destroyAllWindows()\n",
    "x, y, w, h = bbox\n",
    "track_window = (x, y, w, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = (randint(0, 255), randint(0, 255), randint(0, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute hsv histogram\n",
    "roi = frame[y:y+h, x:x+w] # RGB -> BGR\n",
    "hsv_roi = cv2.cvtColor(roi, cv2.COLOR_BGR2HSV)\n",
    "roi_hist = cv2.calcHist([hsv_roi], [0], None, [180], [0,180])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show histogram\n",
    "plt.hist(roi.ravel(), 180, [0, 180])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_hist = cv2.normalize(roi_hist, roi_hist, 0, 255, cv2.NORM_MINMAX)\n",
    "parameters = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_frame_time = 0\n",
    "new_frame_time = 0\n",
    "while True:\n",
    "    flag, frame = cap.read()\n",
    "    if flag == True:\n",
    "        hsv = cv2.cvtColor(frame, cv2.COLOR_BGR2HSV)\n",
    "        dst = cv2.calcBackProject([hsv], [0], roi_hist, [0, 180], 1)\n",
    "\n",
    "        flag, track_window = cv2.CamShift(dst, (x, y, w, h), parameters)\n",
    "        if flag : \n",
    "            pts = cv2.boxPoints(flag)\n",
    "            pts = np.int0(pts)\n",
    "            img = cv2.polylines(frame, [pts], True, 255, 2)\n",
    "        else:\n",
    "            cv2.putText(frame, 'Tracking failure!', (100,80), cv2.FONT_HERSHEY_SIMPLEX, .75, (0,0,255))\n",
    "            \n",
    "        new_frame_time = time.time()\n",
    "        fps = round(1/(new_frame_time-prev_frame_time),2)\n",
    "        prev_frame_time = new_frame_time\n",
    "        cv2.putText(frame,f'Tracker : CamShift, FPS : {fps}HZ', (100, 20), cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255))\n",
    "\n",
    "        cv2.imshow('Camshift tracking', img)\n",
    "        cv2.imshow('Camshift distribution', dst)\n",
    "\n",
    "        if cv2.waitKey(1) == 13:\n",
    "            break\n",
    "    else:\n",
    "        print('Cannot read webcam')\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optical Flow\n",
    "\n",
    "Two techniques exists : Sparse and Dense\n",
    "\n",
    "### Sparse\n",
    "#### Auto generation of points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define parameters\n",
    "parameters_shitomasi = {\n",
    "    'maxCorners' : 100, # maximal number of corner\n",
    "    'qualityLevel' : 0.3, # pourcentage of the maximum corner value to be left out\n",
    "    'minDistance' : 7 # minimal pixel distance between corner\n",
    "}\n",
    "parameters_lucas_kanade = {\n",
    "    'winSize' : (15,15), # minimum size of the pyramid\n",
    "    'maxLevel' : 2, # number of level for the pyramid\n",
    "    'criteria' : (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03) # criteria to track\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.random.randint(0,255, (100, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'walking.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init video\n",
    "video = cv2.VideoCapture(os.path.join(paths['VIDEOS_PATH'],video_name))\n",
    "if not video.isOpened():\n",
    "    print('Error while loading the video!')\n",
    "    sys.exit()\n",
    "flag, frame = video.read()\n",
    "if not flag:\n",
    "    print('Erro while loading the frame!')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to gray scale\n",
    "frame_gray_init = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create edges list([x,y])\n",
    "edges = cv2.goodFeaturesToTrack(frame_gray_init, mask = None, **parameters_shitomasi)\n",
    "mask = np.zeros_like(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No more frame to load.\n"
     ]
    }
   ],
   "source": [
    "# perform tracking\n",
    "prev_frame_time,new_frame_time = 0,0\n",
    "while True:\n",
    "    flag, frame = video.read()\n",
    "    if not flag:\n",
    "        print('No more frame to load.')\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    new_edges, status, errors = cv2.calcOpticalFlowPyrLK(frame_gray_init, frame_gray, edges, None, **parameters_lucas_kanade)\n",
    "\n",
    "    news = new_edges[status == 1]\n",
    "    olds = edges[status == 1]\n",
    "\n",
    "    for i, (new, old) in enumerate(zip(news, olds)):\n",
    "       a, b = new.ravel()\n",
    "       c, d = old.ravel()\n",
    "\n",
    "       mask = cv2.line(mask, (int(a),int(b)), (int(c),int(d)), colors[i].tolist(), 2)\n",
    "       frame = cv2.circle(frame, (int(a),int(b)), 5, colors[i].tolist(), -1)\n",
    "\n",
    "    img = cv2.add(frame, mask)\n",
    "    \n",
    "    new_frame_time = time.time()\n",
    "    fps = round(1/(new_frame_time-prev_frame_time),2)\n",
    "    prev_frame_time = new_frame_time\n",
    "    cv2.putText(img,f'Tracker : OpticalFlow, FPS : {fps}HZ', (100, 20), cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255))\n",
    "\n",
    "    cv2.imshow('Optical flow sparse', img)\n",
    "    if cv2.waitKey(1) == 13: # enter\n",
    "        break\n",
    "\n",
    "    frame_gray_init = frame_gray.copy()\n",
    "    edges = news.reshape(-1,1,2)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "video.release()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select the point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_point(event, x, y, flags, params):\n",
    "    global point, selected_point, old_points\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        point = (x, y)\n",
    "        selected_point = True\n",
    "        old_points = np.array([[x, y]], dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lucas_kanade = {\n",
    "    'winSize' : (15,15), # minimum size of the pyramid\n",
    "    'maxLevel' : 2, # number of level for the pyramid\n",
    "    'criteria' : (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03) # criteria to track\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_line = (randint(0, 255), randint(0, 255), randint(0, 255))\n",
    "color_circle = (randint(0, 255), randint(0, 255), randint(0, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'walking.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init video\n",
    "video = cv2.VideoCapture(os.path.join(paths['VIDEOS_PATH'],video_name))\n",
    "if not video.isOpened():\n",
    "    print('Error while loading the video!')\n",
    "    sys.exit()\n",
    "flag, frame = video.read()\n",
    "if not flag:\n",
    "    print('Erro while loading the frame!')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_gray_init = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "cv2.namedWindow('Sparse')\n",
    "cv2.setMouseCallback('Sparse', select_point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_point = False\n",
    "point = ()\n",
    "old_points = np.array([[]])\n",
    "mask = np.zeros_like(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_frame_time,new_frame_time = 0,0\n",
    "while True:\n",
    "    flag, frame = video.read()\n",
    "    if not flag:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    if selected_point:\n",
    "        cv2.circle(frame, point, 5, (0, 0, 255), 2)\n",
    "\n",
    "        new_points, status, errors = cv2.calcOpticalFlowPyrLK(frame_gray_init, frame_gray,\n",
    "                                                              old_points, None,\n",
    "                                                              **parameters_lucas_kanade)\n",
    "        frame_gray_init = frame_gray.copy()\n",
    "        old_points = new_points\n",
    "\n",
    "        x, y = new_points.ravel()\n",
    "        j, k = old_points.ravel()\n",
    "\n",
    "        mask = cv2.line(mask, (int(x), int(y)), (int(j), int(k)), color_line, 2)\n",
    "        frame = cv2.circle(frame, (int(x), int(y)), 5, color_circle, -1)\n",
    "\n",
    "    img = cv2.add(frame, mask)\n",
    "\n",
    "    new_frame_time = time.time()\n",
    "    fps = round(1/(new_frame_time-prev_frame_time),2)\n",
    "    prev_frame_time = new_frame_time\n",
    "    cv2.putText(img,f'Tracker : OpticalFlow, FPS : {fps}HZ', (100, 20), cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255))\n",
    "\n",
    "    cv2.imshow(\"Sparse\", img)\n",
    "    cv2.imshow(\"Mask\", mask)\n",
    "\n",
    "    key = cv2.waitKey(1)\n",
    "    if key == 27: # esc\n",
    "        break\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dense\n",
    "\n",
    "Useful links:\n",
    "- [opencv Farneback](https://docs.opencv.org/3.4.15/dc/d6b/group__video__track.html#ga5d10ebbd59fe09c5f650289ec0ece5af)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_farneback = {\n",
    "    'pyr_scale' : 0.5, # specifying the image scale (<1) to build pyramids\n",
    "    'levels' : 3, # number of level for the pyramid\n",
    "    'winsize' : 15, # averaging window size\n",
    "    'iterations' : 3, # number of iterations the algorithm does\n",
    "    'poly_n' : 5, # size of the pixel neighborhood\n",
    "    'poly_sigma' : 1.1, # standard deviation of the Gaussian\n",
    "    'flags ' : 0, # operation flags\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_name = 'walking.avi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init video\n",
    "video = cv2.VideoCapture(os.path.join(paths['VIDEOS_PATH'],video_name))\n",
    "if not video.isOpened():\n",
    "    print('Error while loading the video!')\n",
    "    sys.exit()\n",
    "flag, first_frame = video.read()\n",
    "if not flag:\n",
    "    print('Erro while loading the frame!')\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_gray_init = cv2.cvtColor(first_frame, cv2.COLOR_BGR2GRAY)\n",
    "hsv = np.zeros_like(first_frame)\n",
    "hsv[...,1] = 255 # changing value of the saturation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'calcOpticalFlowFarneback'\n> Overload resolution failed:\n>  - calcOpticalFlowFarneback() missing required argument 'flags' (pos 10)\n>  - calcOpticalFlowFarneback() missing required argument 'flags' (pos 10)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m      6\u001b[0m frame_gray \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcvtColor(frame, cv2\u001b[39m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m----> 8\u001b[0m flow \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39;49mcalcOpticalFlowFarneback(frame_gray_init, frame_gray, \u001b[39mNone\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparameters_farneback)\n\u001b[1;32m      9\u001b[0m magnitude, angle \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mcartToPolar(flow[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\u001b[39m0\u001b[39m], flow[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\u001b[39m1\u001b[39m]) \u001b[39m# X, Y axis\u001b[39;00m\n\u001b[1;32m     10\u001b[0m hsv[\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m\u001b[39m.\u001b[39m,\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m angle \u001b[39m*\u001b[39m (\u001b[39m180\u001b[39m \u001b[39m/\u001b[39m (np\u001b[39m.\u001b[39mpi \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m)) \u001b[39m# modify H channel\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) :-1: error: (-5:Bad argument) in function 'calcOpticalFlowFarneback'\n> Overload resolution failed:\n>  - calcOpticalFlowFarneback() missing required argument 'flags' (pos 10)\n>  - calcOpticalFlowFarneback() missing required argument 'flags' (pos 10)\n"
     ]
    }
   ],
   "source": [
    "prev_frame_time,new_frame_time = 0,0\n",
    "while True:\n",
    "    flag, frame = video.read()\n",
    "    if not flag:\n",
    "        break\n",
    "    frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(frame_gray_init, frame_gray, None, **parameters_farneback)\n",
    "    magnitude, angle = cv2.cartToPolar(flow[...,0], flow[...,1]) # X, Y axis\n",
    "    hsv[...,0] = angle * (180 / (np.pi / 2)) # modify H channel\n",
    "    hsv[...,2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX) # modify V channel\n",
    "\n",
    "    frame_rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2BGR)\n",
    "\n",
    "    new_frame_time = time.time()\n",
    "    fps = round(1/(new_frame_time-prev_frame_time),2)\n",
    "    prev_frame_time = new_frame_time\n",
    "    cv2.putText(frame_rgb,f'Tracker : OpticalFlow, FPS : {fps}HZ', (100, 20), cv2.FONT_HERSHEY_SIMPLEX, .75, (0, 0, 255))\n",
    "\n",
    "    cv2.imshow('Dense optical flow', frame_rgb)\n",
    "    if cv2.waitKey(1) == 13: # enter\n",
    "        break\n",
    "\n",
    "    frame_gray_init = frame_gray\n",
    "\n",
    "video.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "df0893f56f349688326838aaeea0de204df53a132722cbd565e54b24a8fec5f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
